name: CI / PR / vllm-rbln with optimum

on:
  workflow_dispatch:
    inputs:
      ref:
        description: "ref to checkout"
        required: false
        type: string
      rebel_compiler_version:
        description: "Version of rebel-compiler to use (optional)"
        required: false
        type: string
      optimum_rbln_version:
        description: "Version of optimum-rbln to use (optional)"
        required: false
        type: string
  workflow_call:
    inputs:
      ref:
        description: "ref to checkout"
        required: false
        type: string
      rebel_compiler_version:
        description: "Version of rebel-compiler to use (optional)"
        required: false
        type: string
      optimum_rbln_version:
        description: "Version of optimum-rbln to use (optional)"
        required: false
        type: string

env:
  REBEL_PYPI_ENDPOINT: ${{ vars.REBEL_PYPI_INTERNAL_ENDPOINT }}
  REBEL_PYPI_USERNAME: ${{ secrets.REBEL_PYPI_USERNAME }}
  REBEL_PYPI_PASSWORD: ${{ secrets.REBEL_PYPI_PASSWORD }}
  REBEL_VLLM_PRE_COMPILED_DIR: ${{ secrets.VLLM_PRE_COMPILED_DIR }}

jobs:
  test_vllm_rbln:
    if: ${{ inputs.rebel_compiler_version && inputs.optimum_rbln_version }}
    runs-on: runner-vllm-ci
    env:
      NUM_INPUT_PROMPT: 1
      RBLN_VERBOSE: 6
      VLLM_LOGGING_LEVEL: DEBUG
    steps:
      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Get latest rebel_compiler version
        if: ${{ !inputs.rebel_compiler_version }}
        id: get_latest_rebel_compiler
        run: |
          echo "LATEST_COMPILER_VER=${{ needs.get-compiler-version.outputs.compiler_version }}" >> $GITHUB_OUTPUT

      - name: Install rebel-compiler
        run: |
          python3 -m pip uninstall rebel-compiler -y
          PYPI_URL=$(echo ${{ env.REBEL_PYPI_ENDPOINT }} | sed "s/\/\//\0${{ env.REBEL_PYPI_USERNAME }}:${{ env.REBEL_PYPI_PASSWORD }}@/")
          VERSION=${{ inputs.rebel_compiler_version || steps.get_latest_rebel_compiler.outputs.LATEST_COMPILER_VER }}
          python3 -m pip install --extra-index-url $PYPI_URL rebel-compiler==${VERSION}

      - name: Checkout current repository
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.pr_number && format('refs/pull/{0}/merge', inputs.pr_number) || inputs.ref || github.sha }}
          submodules: recursive
          fetch-depth: 0

      - name: Uninstall existing vllm-rbln
        run: |
          python3 -m pip uninstall -y vllm-rbln || true

      - name: Build vllm-rbln wheel
        run: |
          python -m pip install build
          python -m build --wheel

      - name: Install local vllm-rbln package and dependencies
        run: |
          pip install packaging setuptools wheel simphile pynvml huggingface_hub setuptools_scm fire
          VERSION=${{ inputs.optimum_rbln_version }}
          if [[ "$VERSION" =~ ^[0-9]+(\.[0-9]+)*([A-Za-z0-9.+-]+)?$ ]]; then
            CONSTRAINT="optimum-rbln==${VERSION}"
          else
            CONSTRAINT="optimum-rbln @ ${VERSION}"
          fi
          pip install --force-reinstall --no-cache-dir dist/vllm_rbln*.whl --constraint <(echo "$CONSTRAINT")
          echo "optimum-rbln installed: $VERSION"

      - name : Run Llava-next (Eager mode) (V1)
        run: >
           python3 examples/optimum/run_llava.py --max_seq_len 32768 --kvcache_partition_len 32768
           --num_input_prompt ${{ env.NUM_INPUT_PROMPT }}
           --model_id ${{ env.REBEL_VLLM_PRE_COMPILED_DIR }}/llava-v1.6-mistral-7b-hf-32k-b4/
      
      - name : Run Llava-next (Eager mode) (V0)
        run: >
           VLLM_USE_V1=0 python3 examples/optimum/run_llava.py --max_seq_len 32768 --kvcache_partition_len 32768
           --num_input_prompt ${{ env.NUM_INPUT_PROMPT }}
           --model_id ${{ env.REBEL_VLLM_PRE_COMPILED_DIR }}/llava-v1.6-mistral-7b-hf-32k-b4/

      - name : Run Llava-next (Flash-attention mode) (V1)
        run: >
          python3 examples/optimum/run_llava.py --max_seq_len 32768 --kvcache_partition_len 16384
          --num_input_prompt ${{ env.NUM_INPUT_PROMPT }}
          --model_id ${{ env.REBEL_VLLM_PRE_COMPILED_DIR }}/llava-v1.6-mistral-7b-hf-32k-b4-kv16k
      
      - name : Run Llava-next (Flash-attention mode) (V0)
        run: >
          VLLM_USE_V1=0 python3 examples/optimum/run_llava.py --max_seq_len 32768 --kvcache_partition_len 16384
          --num_input_prompt ${{ env.NUM_INPUT_PROMPT }}
          --model_id ${{ env.REBEL_VLLM_PRE_COMPILED_DIR }}/llava-v1.6-mistral-7b-hf-32k-b4-kv16k

